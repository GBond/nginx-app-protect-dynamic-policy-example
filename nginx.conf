
user nginx;
worker_processes auto;

error_log /var/log/nginx/error.log notice;
pid /var/run/nginx.pid;

# load_module modules/ngx_http_app_protect_module.so;
load_module modules/ngx_http_js_module.so;

events {
    worker_connections 1024;
}


http {
    include /etc/nginx/mime.types;
    default_type application/octet-stream;

    log_format main
    'remote_addr="$remote_addr", '
    '[time_local=$time_local], '
    'request="$request", '
    'status="$status", '
    'http_referer="$http_referer", '
    'body_bytes_sent="$body_bytes_sent", '
    'Host="$host", '
    'sn="$server_name", '
    'request_time=$request_time, '
    'http_user_agent="$http_user_agent", '
    'http_x_forwarded_for="$http_x_forwarded_for", '
    'request_length="$request_length", '
    'upstream_address="$upstream_addr", '
    'upstream_status="$upstream_status", '
    'upstream_connect_time="$upstream_connect_time", '
    'upstream_header_time="$upstream_header_time", '
    'upstream_response_time="$upstream_response_time", '
    'upstream_response_length="$upstream_response_length"';

    access_log /var/log/nginx/access.log main;

    sendfile on;
    #tcp_nopush     on;

    keepalive_timeout 65;

    #gzip  on;

    #map $http_x_forwarded_for $client_ip {
    #    default     $http_x_forwarded_for;
    # default $remote_addr;
    #}
    keyval_zone zone=one:1m type=string state=/etc/nginx/one.keyval;
    keyval $http_x_forwarded_for $ip_flag zone=one; # Client address is the key,

    #include /etc/nginx/conf.d/*.conf;
    js_import napPolicySelector.js;
    subrequest_output_buffer_size 10m;

    server {
        listen 80;
        server_name localhost;
        proxy_http_version 1.1;

        proxy_set_header X-Forwarded-Server $host;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        proxy_set_header Upgrade $http_upgrade;
        proxy_set_header Connection "upgrade";
        proxy_ignore_client_abort on;

        client_max_body_size 0;
        default_type text/html;

        set $client_ip "";

        # app_protect_enable on;
        # app_protect_security_log_enable on;
        # # send the logs to the logstash instance on our ELK stack.
        # app_protect_security_log "/etc/app_protect/conf/log_default.json" syslog:server=10.1.1.11:5144;

        ## NGINX Plus API monitoring:
        # status_zone arcadia_server;
        status_zone main_service;


        ## in this lab, there are 2 ingress definitions for arcadia
        ## no-waf is the ingress (virtualServer) without NAP enabled
        proxy_set_header Host no-waf.arcadia-finance.io;

        location / {
            # app_protect_enable off;
            # app_protect_security_log_enable off;
            client_max_body_size 0;

            # this executes the njs code to determine if we need to amend the selected security policy
            js_content napPolicySelector.handleRequest;
        }

        location /proxy {
            # app_protect_enable off;
            # app_protect_security_log_enable off;
            client_max_body_size 0;
            default_type text/html;
            return 200 "Hello! I got your URI request - $request_uri\n";
        }

        location /default {
            internal;
            # app_protect_enable on;
            # app_protect_security_log_enable on;
            # app_protect_policy_file app_protect_default_policy;
            proxy_pass http://arcadia_ingress_nodeports$request_uri;
            if ($request_uri = "/files") {
                status_zone backend_service;
            }
            if ($request_uri = "/api") {
                status_zone app2_service;
            }
            if ($request_uri = "/app3") {
                status_zone app3_service;
            }
            # app_protect_security_log "/opt/app_protect/share/defaults/log_all.json" /var/log/app_protect/requests.log;
        }

        location /strict {
            internal;
            # app_protect_enable on;
            # app_protect_security_log_enable on;
            # app_protect_policy_file app_protect_strict_policy;
            proxy_pass http://arcadia_ingress_nodeports$request_uri;
            if ($request_uri = "/files") {
                status_zone backend_service;
            }
            if ($request_uri = "/api") {
                status_zone app2_service;
            }
            if ($request_uri = "/app3") {
                status_zone app3_service;
            }
            # app_protect_security_log "/opt/app_protect/share/defaults/log_all.json" /var/log/app_protect/requests.log;
        }

        location /medium {
            internal;
            # app_protect_enable on;
            # app_protect_security_log_enable on;
            # app_protect_policy_file "/etc/nginx/vanguard_monitoring.json";
            proxy_pass http://arcadia_ingress_nodeports$request_uri;
            if ($request_uri = "/files") {
                status_zone backend_service;
            }
            if ($request_uri = "/api") {
                status_zone app2_service;
            }
            if ($request_uri = "/app3") {
                status_zone app3_service;
            }
            # app_protect_security_log "/opt/app_protect/share/defaults/log_all.json" /var/log/app_protect/requests.log;
        }


        # this location is for updating the config
        # POST to here with JSON for allow/disallow
        # curl 127.0.0.1/nap_config/7/http/keyvals/one -X POST -d '{"71.105.178.190": "friendly", "0.0.0.0/0": "Not_friendly"}'
        # GET from here to pull the config
        # curl 127.0.0.1/nap_config/7/http/keyvals/one > /etc/nginx/one.keyval
        # TODO: add a location to do this as a write out for local storage
        location /nap_config {
            # app_protect_enable off;
            api write=on;

            # protect this house
            allow 127.0.0.1;
            deny all;
        }

    }

    upstream arcadia_ingress_nodeports {
        zone arcadia_ingress_nodeports 128k;
        server rke1:80;
    }


}


# TCP/UDP proxy and load balancing block
#
#stream {
# Example configuration for TCP load balancing
#upstream stream_backend {
#    zone tcp_servers 64k;
#    server backend1.example.com:12345;
#    server backend2.example.com:12345;
#}
#server {
#    listen 12345;
#    status_zone tcp_server;
#    proxy_pass stream_backend;
#}
#}